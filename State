import csv
from copy import deepcopy
from decimal import Decimal

class State:

    def __init__(self, ind, name, actions):
        self.index = ind
        self.name = name
        self.possibleActions = actions
        self.transition = []
        self.reward = []
        self.terminating = False
        self.utility = 0

    def __str__(self):
        print "Index: " + str(self.index) + " Name: " + self.name + " Actions: " + str(self.possibleActions)

    def modifyActions(self, actions):
        self.possibleActions = actions

    def setTransition(self, tran):
        self.transition = tran

    def getTransition(self):
        return self.transition

    def setReward(self, reward):
        self.reward = reward

    def getReward(self):
        return self.reward

    def getIndex(self):
        return self.index

    def getPossibleActions(self):
        return self.possibleActions

    def setPossibleActions(self, act):
        self.possibleActions = act

    def isTerminating(self):
        return self.terminating

    def setTerminating(self, term):
        self.terminating = term
        if term == True:
            self.possibleActions = []

    def setUtility(self, util):
        self.utility = util

    def getUtility(self):
        return self.utility

class Action:

    def __init__(self, ind, name):
        self.index = ind
        self.name = name

    def __str__(self):
        print "Index: " + str(self.index) + " Name: " + self.name

    def getIndex(self):
        return self.index


class MDP:

    def __init__(self, numberOfStates, numberOfActions):
        self.numberOfStates = numberOfStates
        self.numberOfActions = numberOfActions
        self.states = []
        self.actions = []
        self.options = []

    # Define Action
    def initializeActions(self):
        for i in xrange(0, self.numberOfActions):
            a = Action(i, str("a" + str(i)))
            self.actions.append(a)

    # Define States
    def initializeStates(self):
        for i in xrange(0, self.numberOfStates):
            x = State(i, str("s" + str(i)), self.actions)
            self.states.append(x)
        self.states[3].setTerminating(True)
        self.states[3].setUtility(1)
        self.states[7].setTerminating(True)
        self.states[7].setUtility(-1)

    # def northTransition(self):
    #     tosend = []
    #
    #     a = self.actions[0]
    #     for s in self.states:
    #
    #         if s.isTerminating():
    #             continue
    #
    #         ind = s.getIndex()
    #         if ind + 3 < self.numberOfStates:
    #             triple = (a.getIndex(), ind + 3, 0.8)
    #             triplet = (a.getIndex(), ind + 3, 0)
    #         else:
    #             triple = [a.getIndex(), ind, 0.8]
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 2:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         else:
    #             triple = (a.getIndex(), ind + 1, 0.1)
    #             triplet = (a.getIndex(), ind+1, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 0:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         else:
    #             triple = (a.getIndex(), ind - 1, 0.1)
    #             triplet = (a.getIndex(), ind - 1, 0)
    #         if triplet in s.getTransition():
    #             s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #
    # def southTransition(self):
    #     tosend = []
    #     a = self.actions[2]
    #     for s in self.states:
    #
    #         if s.isTerminating():
    #             continue
    #
    #         ind = s.getIndex()
    #         if ind - 3 >= 0:
    #             triple = (a.getIndex(), ind - 3, 0.8)
    #             triplet = (a.getIndex(), ind-3, 0)
    #         else:
    #             triple = (a.getIndex(), ind, 0.8)
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 2:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         else:
    #             triple = (a.getIndex(), ind + 1, 0.1)
    #             triplet = (a.getIndex(), ind+1, 0)
    #         if triplet in s.getTransition():
    #             s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 0:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         else:
    #             triple = (a.getIndex(), ind - 1, 0.1)
    #             triplet = (a.getIndex(), ind-1, 0)
    #         if triplet in s.getTransition():
    #             s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #
    # def westTransition(self):
    #     tosend = []
    #     a = self.actions[3]
    #     for s in self.states:
    #
    #         if s.isTerminating():
    #             continue
    #
    #         ind = s.getIndex()
    #         if ind + 3 < self.numberOfStates:
    #             triple = (a.getIndex(), ind + 3, 0.1)
    #             triplet = (a.getIndex(), ind+3, 0)
    #         else:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind - 3 >= 0:
    #             triple = (a.getIndex(), ind - 3, 0.1)
    #             triplet = (a.getIndex(), ind-3, 0)
    #         else:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 0:
    #             triple = (a.getIndex(), ind, 0.8)
    #             triplet = (a.getIndex(), ind, 0)
    #         else:
    #             triple = (a.getIndex(), ind - 1, 0.8)
    #             triplet = (a.getIndex(), ind-1, 0)
    #         if triplet in s.getTransition():
    #             s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #
    # def eastTransition(self):
    #     tosend = []
    #     a = self.actions[1]
    #     for s in self.states:
    #
    #         if s.isTerminating():
    #             continue
    #
    #         ind = s.getIndex()
    #         if ind + 3 < self.numberOfStates:
    #             triple = (a.getIndex(), ind + 3, 0.1)
    #             triplet = (a.getIndex(), ind+3, 0)
    #         else:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind - 3 >= 0:
    #             triple = (a.getIndex(), ind - 3, 0.1)
    #             triplet = (a.getIndex(), ind-3, 0)
    #         else:
    #             triple = (a.getIndex(), ind, 0.1)
    #             triplet = (a.getIndex(), ind, 0)
    #         s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)
    #
    #         if ind % 3 == 2:
    #             triple = (a.getIndex(), ind, 0.8)
    #             triplet = (a.getIndex(), ind, 0)
    #
    #         else:
    #             triple = (a.getIndex(), ind + 1, 0.8)
    #             triplet = (a.getIndex(), ind+1, 0)
    #         if triplet in s.getTransition():
    #             s.getTransition().remove(triplet)
    #         s.getTransition().append(triple)



    # Leave one line space after each transition table for each action in the data file.
    # TransitionFunction For Actions
    def autoTransitionFunction(self, readfromFile=False):

        # if readfromFile == False:
        #     for a in self.actions:
        #         for s in self.states:
        #             for sd in self.states:
        #                 triple = (a.getIndex(), sd.getIndex(), 0)
        #                 s.getTransition().append(triple)
        #     self.northTransition()
        #     # self.southTransition()
        #     # self.westTransition()
        #     # self.eastTransition()
        # else:
        stateIndex = 0
        actionIndex = 0
        with open('transitionData', 'rb') as csvfile:
            reader = csv.reader(csvfile, delimiter=',')
            for row in reader:
                if len(row) == 0:
                    stateIndex = 0
                    actionIndex = actionIndex + 1
                    continue
                for sp in xrange(0, self.numberOfStates):
                    triple = (actionIndex, sp, float(row[sp]))
                    self.states[stateIndex].getTransition().append(triple)
                stateIndex += 1

        # print len(self.states[6].getTransition())


    # RewardFunctions For Actions
    def autoRewardFunction(self):

        tosend = []
        # if readFromFile == False:
        #     for x in self.states:
        #         if x.isTerminating():
        #             if x.getIndex() == 5:
        #                 triple = (a.getIndex(), -1)
        #             elif x.getIndex() == 8:
        #                 triple = (a.getIndex(), 1)
        #             tosend.append(triple)
        #         else:
        #             for a in self.actions:
        #                 triple = (a.getIndex(), -0.04)
        #                 tosend.append(triple)
        #         x.setReward(tosend)
        # else:
        stateIndex = 0
        with open('rewardData', 'rb') as csvfile:
            reader = csv.reader(csvfile, delimiter=',')
            for row in reader:
                for ap in xrange(0, self.numberOfActions):
                    triple = (ap, float(row[ap]))
                    tosend.append(triple)
                self.states[stateIndex].setReward(tosend)
                tosend = []
                stateIndex += 1

    # Leave one line space after each option in the data file.
    def setOptions(self, readFromFile=False):
        if readFromFile == False:
            return
        else:
            global optionIndex
            optionIndex = 0
            actionIndex = 0
            counter = 0
            tosend = []
            with open('OptionsData', 'rb') as csvfile:
                reader = csv.reader(csvfile, delimiter=',')
                for row in reader:
                    counter += 1

                    if len(row) == 0:

                        o.setPolicy(tosend)
                        optionIndex = optionIndex + 1

                        counter = 0
                        actionIndex = 0
                        continue

                    if counter == 1:
                        o = Option(optionIndex)
                        self.options.append(o)
                        #Initiation
                        # for x in xrange(0, len(row)):
                        #     pass
                        initset = []
                        for x in row:
                            initset.append(int(x))
                        o.setInitiationSet(initset)

                    elif counter == 2:
                        #Beta
                        betaval = []
                        for x in row:
                            betaval.append(float(x))
                        o.setBeta(betaval)

                    elif counter >= 3:
                        #Policy
                        stateIndex = 0
                        for st in self.states:
                            triple = (st.getIndex(), actionIndex, float(row[st.getIndex()]))
                            tosend.append(triple)
                            stateIndex += 1
                        actionIndex += 1


    def calculateRewardForOption(self, state, option, gamma, delta):

        # print gamma
        sums = 0
        # print "State: " + str(state)
        # print "Option: " + str(option)
        if state not in self.options[option].getInitiationSet():
            # print "Not in Initiation Set."
            return  0

        actionsavail = self.states[state].getPossibleActions()

        if len(actionsavail) == 0:
            return 0

        for act in actionsavail:

            # print
            # print "State: " + str(state)
            # print "Action: " + str(act.getIndex())
            sumForAction = 0
            probOfAction = 0
            immReward = 0
            possibleStates = []
            actionSet = self.options[option].getPolicy()

            for x in actionSet:
                if x[0] == state and x[1] == act.getIndex():
                    probOfAction = x[2]
                    break

            # print "Prob Of Action: " + str(probOfAction)

            # if probOfAction == 0:
            #     avail = self.states[state].getPossibleActions()
            #     avail = filter(lambda a: a != act.getIndex(), avail)
            #     self.states[state].setPossibleActions(avail)
            #     continue

            rewards = self.states[state].getReward()
            for x in rewards:
                if x[0] == act.getIndex():
                    immReward = x[1]
                    break

            # print "Imm Reward: " + str(immReward)

            if probOfAction != 0 and gamma > delta:

                transitions = self.states[state].getTransition()

                # print "Transition Function for " + str(state) + " is: " + str(transitions)
                for x in transitions:
                    if x[0] == act.getIndex() and x[2] != 0:
                        possibleStates.append((x[1], x[2]))

                # print "Possible States from " + str(state) + " are: " + str(possibleStates)

                for x in possibleStates:

                    product = 0
                    if len(possibleStates) == 0:
                        break

                    # print "Possible State: " + str(x)


                    sdash = self.states[x[0]]
                    prob = float(x[1])

                    # print "Sdash: " +str(sdash.getIndex())
                    # print "prob: " + str(prob)

                    beta_sdash = float(self.options[option].getBeta()[x[0]])

                    # print "Beta_sdash: " + str(1-beta_sdash)

                    if prob != 0 and (1-beta_sdash) != 0:
                        product = prob * (1 - float(beta_sdash)) * self.calculateRewardForOption(sdash.getIndex(), option, gamma, delta)

                    # print "Product for this state: " + str(product)
                    sumForAction += product


                # print "Sum for Action: " + str(sumForAction)
                sumForAction *= gamma

                sumForAction += immReward

                sumForAction *= probOfAction

                # print "Final Sum For Action: " + str(sumForAction)
                # print

            else:
                # print "Prob of action is 0."
                sumForAction = 0

            # print immReward
            # print probOfAction
            # if sumForAction <= 0:
            #     avail = self.states[state].getPossibleActions()
            #     avail.remove(act.getIndex())
            #     self.states[state].setPossibleActions(avail)

            sums += sumForAction
            # print "Sums: " + str(sums)
            # print

        return sums

    def calculateTransitionForOption(self, state, option, statedash, gamma, delta):

        sums = 0
        # print "State: " + str(state)
        # print "Option: " + str(option)
        # print "Statedash: " + str(statedash)
        if state not in self.options[option].getInitiationSet():
            # print "Not in Initiation Set."
            return 0

        actionsavail = self.states[state].getPossibleActions()

        if len(actionsavail) == 0:
            return 0

        for act in actionsavail:

            # print
            # print "State: " + str(state)
            # print "Action: " + str(act.getIndex())
            sumForAction = 0
            probOfAction = 0
            possibleStates = []
            actionSet = self.options[option].getPolicy()

            for x in actionSet:
                if x[0] == state and x[1] == act.getIndex():
                    probOfAction = x[2]
                    break

            # print "Prob Of Action: " + str(probOfAction)

            # if probOfAction == 0:
            #     avail = self.states[state].getPossibleActions()
            #     avail = filter(lambda a: a != act.getIndex(), avail)
            #     self.states[state].setPossibleActions(avail)
            #     continue

            if probOfAction != 0 and gamma > delta:

                transitions = self.states[state].getTransition()

                # print "Transition Function for " + str(state) + " is: " + str(transitions)
                for x in transitions:
                    if x[0] == act.getIndex() and x[2] != 0:
                        possibleStates.append((x[1], x[2]))

                # print "Possible States from " + str(state) + " are: " + str(possibleStates)

                for x in possibleStates:

                    product = 0
                    if len(possibleStates) == 0:
                        break

                    # print "Possible State: " + str(x)


                    sdash = self.states[x[0]]
                    prob = float(x[1])

                    # print "Sdash: " +str(sdash.getIndex())
                    # print "prob: " + str(prob)

                    beta_sdash = float(self.options[option].getBeta()[x[0]])

                    # print "1-Beta_sdash: " + str(1-beta_sdash)

                    if prob != 0 and float(1 - beta_sdash) != 0:
                        product += ((1 - float(beta_sdash)) * self.calculateTransitionForOption(sdash.getIndex(),
                                                                                                 option, statedash, gamma, delta))

                    if prob != 0 and float(beta_sdash) != 0:
                        product += (beta_sdash * self.delta(float(sdash.getIndex()), float(statedash)))

                    product *= prob

                    # print "Product for this state: " + str(product)
                    sumForAction += product

                # print "Sum for Action: " + str(sumForAction)

                sumForAction *= gamma
                sumForAction *= probOfAction

                # print "Final Sum For Action: " + str(sumForAction)
                # print

            else:
                # print "Prob of action is 0."
                sumForAction = 0

            # print immReward
            # print probOfAction
            # if sumForAction <= 0:
            #     avail = self.states[state].getPossibleActions()
            #     avail.remove(act.getIndex())
            #     self.states[state].setPossibleActions(avail)

            sums += sumForAction
            # print "Sums: " + str(sums)
            # print

        return sums

    def modelActionAsOptions(self, action):
        global optionIndex
        initset = []
        beta = []
        policy = []

        for s in self.states:
            policy.append((s.getIndex(), action.getIndex(), float(1)))
            if s.isTerminating() == True:
                beta.append(float(1))
            else:
                beta.append(float(0))
            if action in s.getPossibleActions():
                initset.append(s.getIndex())

        o = Option(optionIndex)
        self.options.append(o)
        o.setInitiationSet(initset)
        o.setBeta(beta)
        o.setPolicy(policy)
        optionIndex += 1

    def iterativeRewardCalculation(self, option, gamma, delta):

        values = [0]*len(self.states)
        while(True):

            # print "Values : " + str(values)
            prevValues = deepcopy(values)
            dummy = [0]*len(self.states)


            # print "Prev Values: " + str(prevValues)
            # print "Dummy Values: " + str(dummy)
            # print

            max_difference = 0
            for s in self.states:

                # print "Considering state: " + str(s.getIndex())
                # print

                sums = 0
                s = s.getIndex()
                actionsavail = self.states[s].getPossibleActions()

                for actions in actionsavail:

                    # print "Considering state: " + str(s)
                    # print "Considering Action: " + str(actions.getIndex())
                    possibleStates = []
                    valforaction = 0
                    immReward = 0
                    probOfAction = 0
                    actionSet = self.options[option].getPolicy()

                    for x in actionSet:
                        if x[0] == s and x[1] == actions.getIndex():
                            probOfAction = x[2]
                            break


                    rewards = self.states[s].getReward()
                    for x in rewards:
                        if x[0] == actions.getIndex():
                            immReward = x[1]
                            break
                    # print "Probofaction: " + str(probOfAction)
                    # print "immReward: " +str(immReward)
                    transitions = self.states[s].getTransition()

                    # print "Transition Function for " + str(s) + " is: " + str(transitions)
                    for x in transitions:
                        if x[0] == actions.getIndex() and x[2] != 0:
                            possibleStates.append((x[1], x[2]))

                    # print "Possible States: " + str(possibleStates)


                    for x in possibleStates:

                        product = 0
                        prob = float(x[1])
                        sdash = self.states[x[0]]

                        # print "sdash: " + str(sdash.getIndex())
                        beta_sdash = float(self.options[option].getBeta()[x[0]])

                        # print "prob " + str(prob)
                        product = prob * (1-float(beta_sdash)) * prevValues[sdash.getIndex()]

                        # print "product: " + str(product)
                        valforaction += product

                    # print "Value For Action: " + str(valforaction)
                    valforaction *= gamma

                    valforaction += immReward
                    valforaction *= probOfAction


                    # print "Value For Action: " + str(valforaction)

                    sums += valforaction
                    sums = round(sums, 15)

                    # print "Sums: " + str(sums)

                # print "Overall Sums: " + str(sums)
                # print "Not Updated Dummy: " + str(dummy)
                dummy[s] = sums

                # print "Updated Dummy: "+ str(dummy)
                difference = abs(dummy[s] - values[s])

                if difference > max_difference:
                    max_difference = difference

                # print "max_diff: " + str(max_difference)

            if max_difference > delta:
                values = deepcopy(dummy)
            else:
                return  values
                break

    def iterativeTransitionCalculation(self, option, statedash, gamma, delta):

        values = [0]*len(self.states)
        while (True):

            # print "Values : " + str(values)
            prevValues = deepcopy(values)
            dummy = [0]*len(self.states)

            # print "Prev Values: " + str(prevValues)
            # print "Dummy Values: " + str(dummy)
            # print

            max_difference = 0
            for s in self.states:

                # print "Considering state: " + str(s)
                # print

                s = s.getIndex()
                sums = 0

                actionsavail = self.states[s].getPossibleActions()

                for actions in actionsavail:

                    # print "Considering state: " + str(s)
                    # print "Considering Action: " + str(actions.getIndex())
                    possibleStates = []
                    valforaction = 0
                    probOfAction = 0
                    actionSet = self.options[option].getPolicy()

                    for x in actionSet:
                        if x[0] == s and x[1] == actions.getIndex():
                            probOfAction = x[2]
                            break

                    # print "Probofaction: " + str(probOfAction)
                    # print "immReward: " +str(immReward)
                    transitions = self.states[s].getTransition()

                    # print "Transition Function for " + str(state) + " is: " + str(transitions)
                    for x in transitions:
                        if x[0] == actions.getIndex() and x[2] != 0:
                            possibleStates.append((x[1], x[2]))

                    # print "Possible States: " + str(possibleStates)


                    for x in possibleStates:
                        product = 0
                        prob = float(x[1])
                        sdash = self.states[x[0]]

                        # print "sdash: " + str(sdash.getIndex())
                        beta_sdash = float(self.options[option].getBeta()[x[0]])


                        product =  (1-float(beta_sdash)) * prevValues[sdash.getIndex()]

                        product += float(beta_sdash) * self.delta(sdash.getIndex(), statedash)

                        product *= prob
                        # print "product: " + str(product)
                        valforaction += product

                    # print "Value For Action: " + str(valforaction)
                    valforaction *= gamma
                    valforaction *= probOfAction

                    # print "Value For Action: " + str(valforaction)

                    sums += valforaction
                    sums = round(sums, 15)

                    # print "Sums: " + str(sums)

                # print "Overall Sums: " + str(sums)
                # print "Not Updated Dummy: " + str(dummy)
                dummy[s] = sums

                # print "Updated Dummy: "+ str(dummy)
                difference = abs(dummy[s] - values[s])

                if difference > max_difference:
                    max_difference = difference

                    # print "max_diff: " + str(max_difference)

            if max_difference > delta:
                values = deepcopy(dummy)
            else:
                return values
                break


    def actionsVI(self, gamma, delta):

        values = [x.getUtility() for x in self.states]
        bestactions = [None]*len(self.states)

        while(True):
            prevvalues = deepcopy(values)
            dummy = [0] * len(self.states)
            dummyActions = [None]*len(self.states)

            max_difference = 0
            for s in self.states:

                if s.isTerminating():
                    dummy[s.getIndex()] = prevvalues[s.getIndex()]
                    continue

                max_value = float('-INF')
                for a in s.getPossibleActions():

                    sum = 0
                    reward = [x[1] for x in self.states[s.getIndex()].getReward() if x[0] == a.getIndex()][0]
                    possiblestates = [(x[1], x[2]) for x in self.states[s.getIndex()].getTransition() if x[0] == a.getIndex() and x[2] != 0]
                    for x in possiblestates:

                        prob = float(x[1])
                        sdash = self.states[x[0]]
                        sum += (prob * prevvalues[x[0]])

                    sum *= gamma
                    sum += float(reward)

                    if sum >= max_value:
                        max_value = sum
                        dummyActions[s.getIndex()] = a

                dummy[s.getIndex()] = max_value

                difference = abs(dummy[s.getIndex()] - values[s.getIndex()])
                if difference > max_difference:
                    max_difference = difference

            if max_difference > delta:
                values = deepcopy(dummy)
                bestactions = deepcopy(dummyActions)
            else:
                break

        return values, bestactions


    def delta(self, state, statedash):
        if state == statedash:
            return 1
        else:
            return 0

    def getStates(self):
        return self.states

    def getActions(self):
        return self.actions

    def getOptions(self):
        return self.options


class Option:

    def __init__(self, ind):
        self.index = ind
        self.initiation = []
        self.beta = []
        self.policy = []

    def setInitiationSet(self, init):
        self.initiation = init

    def setBeta(self, beta):
        self.beta = beta

    def setPolicy(self, pol):
        self.policy = pol

    def getInitiationSet(self):
        return self.initiation

    def getIndex(self):
        return self.index

    def getPolicy(self):
        return self.policy

    def getBeta(self):
        return self.beta

    def __str__(self):
        print "Index: " + str(self.index) + " Initiation: " + str(self.initiation)
        print "Beta: " + str(self.beta) + " Policy: " + str(self.policy)

class Driver:
    a = MDP(12, 4)
    a.initializeActions()
    a.initializeStates()
    a.autoTransitionFunction()
    a.autoRewardFunction()
    a.setOptions()
    global absGamma, optionIndex
    absGamma = 1

        # print x.getReward()
    # print a.calculateRewardForOption(0, 0, absGamma, 0.0000001)
    # for x in xrange(0,4):
    #     for y in xrange(0,4):
    #         print a.calculateTransitionForOption(x,0,y, absGamma, 0.0001)
    # actions = a.getActions()
    for x in a.getActions():
        a.modelActionAsOptions(x)
    # o = a.getOptions()

    # print a.iterativeRewardCalculation(0, absGamma, 0.01)
    # for x in xrange(0,4):
    #     print a.calculateRewardForOption(x, 0, absGamma, 0.01)
    # print a.iterativeTransitionCalculation(0, 1, absGamma, 0.0001)
    # s = a.getStates()
    # print s[4].getTransition()
    # print s[4].getReward()
    val, act = a.actionsVI(absGamma, 0.0001)
    print val
    for x in act:
        if x is None:
            print None,
        else:
            print x.getIndex(),